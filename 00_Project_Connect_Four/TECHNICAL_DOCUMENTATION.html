<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Connect 3 AI - Technical Documentation</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: #333;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            padding: 20px;
        }
        
        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            border-radius: 15px;
            box-shadow: 0 10px 40px rgba(0,0,0,0.3);
            overflow: hidden;
        }
        
        header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 40px;
            text-align: center;
        }
        
        header h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
        }
        
        header p {
            font-size: 1.2em;
            opacity: 0.9;
        }
        
        .content {
            padding: 40px;
        }
        
        h2 {
            color: #667eea;
            margin: 30px 0 15px 0;
            font-size: 2em;
            border-bottom: 3px solid #667eea;
            padding-bottom: 10px;
        }
        
        h3 {
            color: #764ba2;
            margin: 25px 0 10px 0;
            font-size: 1.5em;
        }
        
        h4 {
            color: #555;
            margin: 20px 0 10px 0;
            font-size: 1.2em;
        }
        
        .section {
            margin-bottom: 40px;
            padding: 20px;
            background: #f8f9fa;
            border-radius: 10px;
            border-left: 5px solid #667eea;
        }
        
        .code-block {
            background: #2d2d2d;
            color: #f8f8f2;
            padding: 20px;
            border-radius: 8px;
            overflow-x: auto;
            margin: 15px 0;
            font-family: 'Courier New', monospace;
            font-size: 0.9em;
            line-height: 1.5;
        }
        
        .code-block .comment {
            color: #75715e;
        }
        
        .code-block .keyword {
            color: #66d9ef;
        }
        
        .code-block .string {
            color: #e6db74;
        }
        
        .code-block .function {
            color: #a6e22e;
        }
        
        .code-block .number {
            color: #ae81ff;
        }
        
        .diagram {
            background: white;
            border: 2px solid #667eea;
            border-radius: 10px;
            padding: 30px;
            margin: 20px 0;
            text-align: center;
        }
        
        .flow-step {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 15px 25px;
            border-radius: 8px;
            margin: 10px;
            display: inline-block;
            font-weight: bold;
            box-shadow: 0 4px 10px rgba(0,0,0,0.2);
        }
        
        .arrow {
            font-size: 2em;
            color: #667eea;
            margin: 10px 0;
        }
        
        .data-table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        
        .data-table th {
            background: #667eea;
            color: white;
            padding: 15px;
            text-align: left;
            font-weight: bold;
        }
        
        .data-table td {
            padding: 12px 15px;
            border-bottom: 1px solid #ddd;
        }
        
        .data-table tr:nth-child(even) {
            background: #f8f9fa;
        }
        
        .data-table tr:hover {
            background: #e9ecef;
        }
        
        .highlight {
            background: #fff3cd;
            padding: 15px;
            border-left: 4px solid #ffc107;
            border-radius: 5px;
            margin: 15px 0;
        }
        
        .info-box {
            background: #d1ecf1;
            border: 1px solid #bee5eb;
            border-radius: 8px;
            padding: 20px;
            margin: 20px 0;
        }
        
        .info-box h4 {
            color: #0c5460;
            margin-top: 0;
        }
        
        .warning-box {
            background: #f8d7da;
            border: 1px solid #f5c6cb;
            border-radius: 8px;
            padding: 20px;
            margin: 20px 0;
        }
        
        .warning-box h4 {
            color: #721c24;
            margin-top: 0;
        }
        
        .success-box {
            background: #d4edda;
            border: 1px solid #c3e6cb;
            border-radius: 8px;
            padding: 20px;
            margin: 20px 0;
        }
        
        .success-box h4 {
            color: #155724;
            margin-top: 0;
        }
        
        .math {
            font-family: 'Times New Roman', serif;
            font-style: italic;
            padding: 10px;
            background: #f0f0f0;
            border-radius: 5px;
            margin: 10px 0;
            text-align: center;
        }
        
        ul, ol {
            margin: 15px 0 15px 30px;
        }
        
        li {
            margin: 8px 0;
        }
        
        .grid-container {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }
        
        .card {
            background: white;
            border: 2px solid #667eea;
            border-radius: 10px;
            padding: 20px;
            box-shadow: 0 4px 10px rgba(0,0,0,0.1);
        }
        
        .card h4 {
            color: #667eea;
            margin-top: 0;
        }
        
        footer {
            background: #2d2d2d;
            color: white;
            text-align: center;
            padding: 20px;
            margin-top: 40px;
        }
        
        .toc {
            background: #f8f9fa;
            border: 2px solid #667eea;
            border-radius: 10px;
            padding: 25px;
            margin: 30px 0;
        }
        
        .toc h3 {
            color: #667eea;
            margin-top: 0;
        }
        
        .toc ul {
            list-style: none;
            margin-left: 0;
        }
        
        .toc li {
            margin: 10px 0;
        }
        
        .toc a {
            color: #764ba2;
            text-decoration: none;
            font-weight: 500;
            transition: color 0.3s;
        }
        
        .toc a:hover {
            color: #667eea;
            text-decoration: underline;
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>üéÆ Connect 3 AI: Technical Documentation</h1>
            <p>Complete Guide to Data Collection, Neural Network Architecture, and Model Deployment</p>
        </header>
        
        <div class="content">
            <!-- Table of Contents -->
            <div class="toc">
                <h3>üìë Table of Contents</h3>
                <ul>
                    <li><a href="#overview">1. System Overview</a></li>
                    <li><a href="#data-collection">2. Data Collection Pipeline</a></li>
                    <li><a href="#data-structure">3. Data Structure & Format</a></li>
                    <li><a href="#data-transformation">4. Data Transformation for Neural Networks</a></li>
                    <li><a href="#neural-network">5. Neural Network Architecture</a></li>
                    <li><a href="#training">6. Training Process</a></li>
                    <li><a href="#post-training">7. Post-Training: Model Deployment</a></li>
                    <li><a href="#mathematical">8. Mathematical Details</a></li>
                    <li><a href="#performance">9. Performance Metrics</a></li>
                </ul>
            </div>

            <!-- Section 1: Overview -->
            <section id="overview" class="section">
                <h2>1. System Overview</h2>
                
                <p>The Connect 3 AI system is an <strong>imitation learning</strong> pipeline that learns to play Connect 3 by observing human gameplay. The system consists of four main components:</p>
                
                <div class="diagram">
                    <div class="flow-step">1. Data Collection<br/>(Human Plays Games)</div>
                    <div class="arrow">‚Üì</div>
                    <div class="flow-step">2. Data Storage<br/>(NPZ Format)</div>
                    <div class="arrow">‚Üì</div>
                    <div class="flow-step">3. Neural Network Training<br/>(PyTorch CNN)</div>
                    <div class="arrow">‚Üì</div>
                    <div class="flow-step">4. Model Deployment<br/>(.pth Model File)</div>
                </div>
                
                <div class="info-box">
                    <h4>üéØ Learning Paradigm: Supervised Imitation Learning</h4>
                    <p>The AI learns by <strong>imitating</strong> human decisions. Given a board state, it predicts which position a human player would choose. This is a supervised learning task where:</p>
                    <ul>
                        <li><strong>Input (X):</strong> Board state (4√ó4 grid)</li>
                        <li><strong>Output (Y):</strong> Position chosen by human player (0-15)</li>
                        <li><strong>Goal:</strong> Minimize prediction error on human moves</li>
                    </ul>
                </div>
            </section>

            <!-- Section 2: Data Collection -->
            <section id="data-collection" class="section">
                <h2>2. Data Collection Pipeline</h2>
                
                <h3>2.1 Game Flow</h3>
                <p>Data collection happens during human gameplay sessions. The system records every decision made by the human player (Player 1).</p>
                
                <div class="code-block">
<span class="comment"># File: src/play_human.py</span>
<span class="keyword">def</span> <span class="function">play_and_record</span>(num_games, save_path):
    env = ConnectFourEnv()
    
    <span class="comment"># Storage for all games</span>
    all_states = []      <span class="comment"># Board configurations</span>
    all_players = []     <span class="comment"># Which player moved (1 or -1)</span>
    all_actions = []     <span class="comment"># Position chosen (flat index 0-15)</span>
    
    <span class="keyword">for</span> g <span class="keyword">in</span> range(num_games):
        (state, player) = env.reset()
        done = <span class="keyword">False</span>
        
        <span class="keyword">while</span> <span class="keyword">not</span> done:
            env.render()
            valid = env.valid_actions()
            
            <span class="keyword">if</span> player == <span class="number">1</span>:  <span class="comment"># Human turn</span>
                <span class="comment"># Human enters: "row col" (e.g., "0 1")</span>
                user_input = input(<span class="string">"Enter row and column: "</span>).strip()
                row, col = map(int, user_input.split())
                a = (row, col)
                
                <span class="comment"># RECORD THIS DECISION</span>
                all_states.append(state.copy())
                all_players.append(player)
                flat_action = row * <span class="number">4</span> + col  <span class="comment"># Convert to flat index</span>
                all_actions.append(flat_action)
            
            <span class="keyword">else</span>:  <span class="comment"># Random opponent turn</span>
                a = random.choice(valid)
                <span class="comment"># Opponent moves are NOT recorded</span>
            
            (state, player), reward, done, _ = env.step(a)
    
    <span class="comment"># Save all recorded data</span>
    boards = np.stack(all_states)     <span class="comment"># Shape: (N, 4, 4)</span>
    players = np.array(all_players)   <span class="comment"># Shape: (N,)</span>
    actions = np.array(all_actions)   <span class="comment"># Shape: (N,)</span>
    
    np.savez(save_path, boards=boards, players=players, actions=actions)
                </div>
                
                <h3>2.2 What Gets Recorded?</h3>
                <table class="data-table">
                    <thead>
                        <tr>
                            <th>Data Component</th>
                            <th>What It Contains</th>
                            <th>Why We Need It</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>Board State</strong></td>
                            <td>4√ó4 array with values: 0 (empty), 1 (Player 1), -1 (Player 2)</td>
                            <td>The "situation" the player faced when making a decision</td>
                        </tr>
                        <tr>
                            <td><strong>Player ID</strong></td>
                            <td>1 (human) or -1 (opponent)</td>
                            <td>Identifies whose perspective to encode (important for board representation)</td>
                        </tr>
                        <tr>
                            <td><strong>Action (Position)</strong></td>
                            <td>Flat index 0-15 representing board position</td>
                            <td>The "correct answer" - what the human chose to do</td>
                        </tr>
                    </tbody>
                </table>
                
                <div class="highlight">
                    <strong>üîë Key Insight:</strong> We only record <strong>human player decisions</strong>. The random opponent's moves are not used for training because we want to learn good strategy, not random play!
                </div>
                
                <h3>2.3 Position Encoding</h3>
                <p>Board positions are converted to flat indices for consistency:</p>
                <div class="math">
                    flat_index = row √ó 4 + col
                    <br/><br/>
                    Examples:<br/>
                    Position (0, 0) ‚Üí Index 0<br/>
                    Position (0, 1) ‚Üí Index 1<br/>
                    Position (1, 2) ‚Üí Index 6<br/>
                    Position (3, 3) ‚Üí Index 15
                </div>
            </section>

            <!-- Section 3: Data Structure -->
            <section id="data-structure" class="section">
                <h2>3. Data Structure & Format</h2>
                
                <h3>3.1 NPZ File Format</h3>
                <p>All collected data is saved in a single <code>.npz</code> (NumPy compressed archive) file:</p>
                
                <div class="code-block">
<span class="comment"># File: data/human_games.npz</span>
{
    <span class="string">'boards'</span>: numpy array of shape (N, <span class="number">4</span>, <span class="number">4</span>), dtype=int8,
    <span class="string">'players'</span>: numpy array of shape (N,), dtype=int8,
    <span class="string">'actions'</span>: numpy array of shape (N,), dtype=int64
}

<span class="comment"># Where N = total number of moves recorded across all games</span>
                </div>
                
                <h3>3.2 Data Example</h3>
                <p>Let's walk through a concrete example:</p>
                
                <div class="info-box">
                    <h4>Example Game State</h4>
                    <p><strong>Board Configuration:</strong></p>
                    <pre>
    Col: 0   1   2   3
Row 0: [¬∑] [X] [¬∑] [¬∑]
Row 1: [¬∑] [¬∑] [O] [¬∑]
Row 2: [¬∑] [¬∑] [¬∑] [¬∑]
Row 3: [¬∑] [¬∑] [¬∑] [¬∑]
                    </pre>
                    <p><strong>Stored as NumPy array:</strong></p>
                    <pre>
[[0,  1, 0, 0],
 [0,  0, -1, 0],
 [0,  0, 0, 0],
 [0,  0, 0, 0]]
                    </pre>
                    <p><strong>Human's Next Move:</strong> Places X at position (2, 1)</p>
                    <p><strong>Stored Action:</strong> flat_index = 2 √ó 4 + 1 = 9</p>
                </div>
                
                <h3>3.3 Data Statistics</h3>
                <p>Typical dataset characteristics:</p>
                
                <div class="grid-container">
                    <div class="card">
                        <h4>üìä Dataset Size</h4>
                        <p><strong>10 games:</strong> ~40-80 moves</p>
                        <p><strong>20 games:</strong> ~80-160 moves</p>
                        <p><strong>50 games:</strong> ~200-400 moves</p>
                        <p><em>Depends on game length and strategy</em></p>
                    </div>
                    
                    <div class="card">
                        <h4>üíæ Memory Usage</h4>
                        <p><strong>Per Move:</strong> ~52 bytes</p>
                        <ul>
                            <li>Board: 4√ó4√ó1 = 16 bytes</li>
                            <li>Player: 1 byte</li>
                            <li>Action: 8 bytes</li>
                            <li>Overhead: ~27 bytes</li>
                        </ul>
                    </div>
                    
                    <div class="card">
                        <h4>üéØ Data Quality</h4>
                        <p><strong>Key Factors:</strong></p>
                        <ul>
                            <li>Player skill level</li>
                            <li>Strategy diversity</li>
                            <li>Game outcome distribution</li>
                            <li>Position coverage</li>
                        </ul>
                    </div>
                </div>
            </section>

            <!-- Section 4: Data Transformation -->
            <section id="data-transformation" class="section">
                <h2>4. Data Transformation for Neural Networks</h2>
                
                <h3>4.1 Why Transform?</h3>
                <p>Raw board data needs transformation because:</p>
                <ul>
                    <li>Neural networks need <strong>fixed-size numerical inputs</strong></li>
                    <li>We want the network to learn <strong>perspective-invariant</strong> patterns</li>
                    <li>We need to clearly distinguish <strong>our pieces vs opponent pieces</strong></li>
                </ul>
                
                <h3>4.2 Two-Channel Encoding</h3>
                <p>The board is converted from a single 4√ó4 array to a 2√ó4√ó4 tensor:</p>
                
                <div class="diagram">
                    <h4>Transformation Process</h4>
                    <div style="text-align: left; max-width: 600px; margin: 20px auto;">
                        <strong>Input Board (4√ó4):</strong>
                        <pre>
[[0,  1,  0,  0],
 [0,  0, -1,  0],
 [0,  1,  0,  0],
 [0,  0,  0, -1]]
                        </pre>
                        <div class="arrow">‚Üì Transform to Current Player's Perspective ‚Üì</div>
                        <strong>Channel 0 (Current Player):</strong>
                        <pre>
[[0, 1, 0, 0],     <span style="color: green;">‚Üê Locations where current player has pieces</span>
 [0, 0, 0, 0],
 [0, 1, 0, 0],
 [0, 0, 0, 0]]
                        </pre>
                        <strong>Channel 1 (Opponent):</strong>
                        <pre>
[[0, 0, 0, 0],     <span style="color: red;">‚Üê Locations where opponent has pieces</span>
 [0, 0, 1, 0],
 [0, 0, 0, 0],
 [0, 0, 0, 1]]
                        </pre>
                    </div>
                </div>
                
                <div class="code-block">
<span class="comment"># File: src/dataset.py - PyTorch Dataset</span>
<span class="keyword">class</span> <span class="function">ConnectFourDataset</span>(Dataset):
    <span class="keyword">def</span> <span class="function">__getitem__</span>(self, idx):
        board = self.boards[idx]      <span class="comment"># (4, 4) array</span>
        player = self.players[idx]    <span class="comment"># 1 or -1</span>
        action = self.actions[idx]    <span class="comment"># 0-15</span>
        
        <span class="comment"># Create two-channel representation</span>
        <span class="keyword">if</span> player == <span class="number">1</span>:
            current = (board == <span class="number">1</span>).astype(<span class="string">"float32"</span>)   <span class="comment"># Player 1's pieces</span>
            opponent = (board == <span class="number">-1</span>).astype(<span class="string">"float32"</span>) <span class="comment"># Player 2's pieces</span>
        <span class="keyword">else</span>:
            current = (board == <span class="number">-1</span>).astype(<span class="string">"float32"</span>)  <span class="comment"># Player 2's pieces</span>
            opponent = (board == <span class="number">1</span>).astype(<span class="string">"float32"</span>)  <span class="comment"># Player 1's pieces</span>
        
        x = np.stack([current, opponent], axis=<span class="number">0</span>)  <span class="comment"># Shape: (2, 4, 4)</span>
        x = torch.from_numpy(x)                    <span class="comment"># Convert to PyTorch tensor</span>
        y = torch.tensor(action, dtype=torch.long) <span class="comment"># Target action</span>
        
        <span class="keyword">return</span> x, y
                </div>
                
                <div class="highlight">
                    <strong>üß† Why Two Channels?</strong><br/>
                    This encoding allows the network to learn <strong>position-independent</strong> strategies. Whether you're X or O, the same patterns (like "block opponent's three-in-a-row") apply. The network learns "where are MY pieces" and "where are OPPONENT pieces" rather than memorizing X vs O positions.
                </div>
                
                <h3>4.3 Batch Processing</h3>
                <p>During training, multiple samples are grouped into batches:</p>
                
                <div class="math">
                    Single Sample: (2, 4, 4) ‚Üí Batch of 64: (64, 2, 4, 4)
                    <br/><br/>
                    Dimensions: (Batch Size, Channels, Height, Width)
                </div>
                
                <table class="data-table">
                    <thead>
                        <tr>
                            <th>Dimension</th>
                            <th>Size</th>
                            <th>Meaning</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>Batch</td>
                            <td>64 (default)</td>
                            <td>Number of game states processed together</td>
                        </tr>
                        <tr>
                            <td>Channels</td>
                            <td>2</td>
                            <td>Current player (0) and Opponent (1)</td>
                        </tr>
                        <tr>
                            <td>Height</td>
                            <td>4</td>
                            <td>Board rows</td>
                        </tr>
                        <tr>
                            <td>Width</td>
                            <td>4</td>
                            <td>Board columns</td>
                        </tr>
                    </tbody>
                </table>
            </section>

            <!-- Section 5: Neural Network -->
            <section id="neural-network" class="section">
                <h2>5. Neural Network Architecture</h2>
                
                <h3>5.1 Overview</h3>
                <p>The ConnectFourNet is a <strong>Convolutional Neural Network (CNN)</strong> designed specifically for spatial board game understanding.</p>
                
                <div class="info-box">
                    <h4>Why CNN for Board Games?</h4>
                    <p>CNNs are perfect for board games because:</p>
                    <ul>
                        <li><strong>Spatial patterns:</strong> Winning patterns (3-in-a-row) are spatial and translation-invariant</li>
                        <li><strong>Local features:</strong> CNNs detect local patterns (like "two pieces in a row")</li>
                        <li><strong>Parameter efficiency:</strong> Shared weights across board positions</li>
                        <li><strong>Hierarchical learning:</strong> Low-level (edges) ‚Üí High-level (strategic patterns)</li>
                    </ul>
                </div>
                
                <h3>5.2 Layer-by-Layer Architecture</h3>
                
                <div class="code-block">
<span class="comment"># File: models/connect_four_net.py</span>
<span class="keyword">class</span> <span class="function">ConnectFourNet</span>(nn.Module):
    <span class="keyword">def</span> <span class="function">__init__</span>(self):
        super().__init__()
        self.conv1 = nn.Conv2d(<span class="number">2</span>, <span class="number">32</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)
        self.conv2 = nn.Conv2d(<span class="number">32</span>, <span class="number">64</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)
        self.fc1 = nn.Linear(<span class="number">64</span> * <span class="number">4</span> * <span class="number">4</span>, <span class="number">128</span>)
        self.fc2 = nn.Linear(<span class="number">128</span>, <span class="number">16</span>)
    
    <span class="keyword">def</span> <span class="function">forward</span>(self, x):
        <span class="comment"># x shape: (batch, 2, 4, 4)</span>
        x = F.relu(self.conv1(x))  <span class="comment"># ‚Üí (batch, 32, 4, 4)</span>
        x = F.relu(self.conv2(x))  <span class="comment"># ‚Üí (batch, 64, 4, 4)</span>
        x = x.view(x.size(<span class="number">0</span>), <span class="number">-1</span>)  <span class="comment"># ‚Üí (batch, 1024)</span>
        x = F.relu(self.fc1(x))    <span class="comment"># ‚Üí (batch, 128)</span>
        logits = self.fc2(x)       <span class="comment"># ‚Üí (batch, 16)</span>
        <span class="keyword">return</span> logits
                </div>
                
                <h3>5.3 Detailed Layer Analysis</h3>
                
                <div class="grid-container">
                    <div class="card">
                        <h4>Layer 1: Conv2D (2‚Üí32)</h4>
                        <p><strong>Input:</strong> (batch, 2, 4, 4)</p>
                        <p><strong>Output:</strong> (batch, 32, 4, 4)</p>
                        <p><strong>Parameters:</strong> 608</p>
                        <p><strong>Function:</strong> Detects 32 different low-level features (edges, corners, adjacent pieces)</p>
                        <p><strong>Kernel:</strong> 3√ó3 with padding=1 (preserves spatial dimensions)</p>
                    </div>
                    
                    <div class="card">
                        <h4>Layer 2: Conv2D (32‚Üí64)</h4>
                        <p><strong>Input:</strong> (batch, 32, 4, 4)</p>
                        <p><strong>Output:</strong> (batch, 64, 4, 4)</p>
                        <p><strong>Parameters:</strong> 18,496</p>
                        <p><strong>Function:</strong> Combines low-level features into 64 high-level patterns (like "two in a row", "blocking positions")</p>
                        <p><strong>Kernel:</strong> 3√ó3 with padding=1</p>
                    </div>
                    
                    <div class="card">
                        <h4>Layer 3: Flatten</h4>
                        <p><strong>Input:</strong> (batch, 64, 4, 4)</p>
                        <p><strong>Output:</strong> (batch, 1024)</p>
                        <p><strong>Parameters:</strong> 0 (reshaping)</p>
                        <p><strong>Function:</strong> Converts 2D feature maps to 1D vector for fully connected layers</p>
                        <p><strong>Calculation:</strong> 64 √ó 4 √ó 4 = 1024</p>
                    </div>
                    
                    <div class="card">
                        <h4>Layer 4: FC (1024‚Üí128)</h4>
                        <p><strong>Input:</strong> (batch, 1024)</p>
                        <p><strong>Output:</strong> (batch, 128)</p>
                        <p><strong>Parameters:</strong> 131,200</p>
                        <p><strong>Function:</strong> Learns strategic combinations of spatial features</p>
                        <p><strong>Purpose:</strong> Compresses information while maintaining decision-relevant features</p>
                    </div>
                    
                    <div class="card">
                        <h4>Layer 5: FC (128‚Üí16)</h4>
                        <p><strong>Input:</strong> (batch, 128)</p>
                        <p><strong>Output:</strong> (batch, 16)</p>
                        <p><strong>Parameters:</strong> 2,064</p>
                        <p><strong>Function:</strong> Produces 16 logits (one per board position)</p>
                        <p><strong>Interpretation:</strong> Higher logit = more likely to place piece there</p>
                    </div>
                    
                    <div class="card">
                        <h4>Activation: ReLU</h4>
                        <p><strong>Formula:</strong> ReLU(x) = max(0, x)</p>
                        <p><strong>Purpose:</strong> Introduces non-linearity</p>
                        <p><strong>Why:</strong> Allows network to learn complex, non-linear patterns</p>
                        <p><strong>Benefits:</strong> Fast computation, no gradient vanishing</p>
                    </div>
                </div>
                
                <h3>5.4 Network Statistics</h3>
                
                <table class="data-table">
                    <thead>
                        <tr>
                            <th>Metric</th>
                            <th>Value</th>
                            <th>Notes</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>Total Parameters</td>
                            <td>152,368</td>
                            <td>All trainable weights and biases</td>
                        </tr>
                        <tr>
                            <td>Model Size</td>
                            <td>~600 KB</td>
                            <td>When saved as .pth file (float32)</td>
                        </tr>
                        <tr>
                            <td>Memory (Training)</td>
                            <td>~50 MB</td>
                            <td>Includes gradients and activations (batch=64)</td>
                        </tr>
                        <tr>
                            <td>Inference Time</td>
                            <td>~2-5 ms</td>
                            <td>Per move on CPU</td>
                        </tr>
                        <tr>
                            <td>FLOPs</td>
                            <td>~300K</td>
                            <td>Floating point operations per forward pass</td>
                        </tr>
                    </tbody>
                </table>
                
                <h3>5.5 Mathematical Flow</h3>
                
                <div class="math">
                    <strong>Forward Pass Equations:</strong><br/><br/>
                    h‚ÇÅ = ReLU(Conv2D(x, W‚ÇÅ) + b‚ÇÅ)         [Shape: 32√ó4√ó4]<br/>
                    h‚ÇÇ = ReLU(Conv2D(h‚ÇÅ, W‚ÇÇ) + b‚ÇÇ)        [Shape: 64√ó4√ó4]<br/>
                    h‚ÇÉ = Flatten(h‚ÇÇ)                       [Shape: 1024]<br/>
                    h‚ÇÑ = ReLU(h‚ÇÉ ¬∑ W‚ÇÉ + b‚ÇÉ)                [Shape: 128]<br/>
                    logits = h‚ÇÑ ¬∑ W‚ÇÑ + b‚ÇÑ                  [Shape: 16]<br/><br/>
                    
                    <strong>Output Interpretation:</strong><br/>
                    P(position i) = softmax(logits)·µ¢ = exp(logits·µ¢) / Œ£‚±º exp(logits‚±º)
                </div>
            </section>

            <!-- Section 6: Training -->
            <section id="training" class="section">
                <h2>6. Training Process</h2>
                
                <h3>6.1 Training Pipeline</h3>
                
                <div class="diagram">
                    <h4>Training Loop</h4>
                    <div class="flow-step">Load Data<br/>(90% train, 10% validation)</div>
                    <div class="arrow">‚Üì</div>
                    <div class="flow-step">Create Batches<br/>(64 samples per batch)</div>
                    <div class="arrow">‚Üì</div>
                    <div class="flow-step">Forward Pass<br/>(Get predictions)</div>
                    <div class="arrow">‚Üì</div>
                    <div class="flow-step">Compute Loss<br/>(CrossEntropyLoss)</div>
                    <div class="arrow">‚Üì</div>
                    <div class="flow-step">Backward Pass<br/>(Compute gradients)</div>
                    <div class="arrow">‚Üì</div>
                    <div class="flow-step">Update Weights<br/>(Adam optimizer)</div>
                    <div class="arrow">‚Üì</div>
                    <div class="flow-step">Validate<br/>(Check accuracy)</div>
                    <div class="arrow">‚Üì</div>
                    <div class="flow-step">Repeat for N Epochs</div>
                </div>
                
                <h3>6.2 Training Code</h3>
                
                <div class="code-block">
<span class="comment"># File: src/train.py</span>
<span class="keyword">def</span> <span class="function">train_model</span>(data_path, epochs=<span class="number">20</span>, batch_size=<span class="number">64</span>, lr=<span class="number">1e-3</span>):
    <span class="comment"># 1. Load dataset</span>
    dataset = ConnectFourDataset(data_path)
    
    <span class="comment"># 2. Split into train/validation (90/10)</span>
    val_size = max(<span class="number">1</span>, int(<span class="number">0.1</span> * len(dataset)))
    train_size = len(dataset) - val_size
    train_ds, val_ds = random_split(dataset, [train_size, val_size])
    
    <span class="comment"># 3. Create data loaders</span>
    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=<span class="keyword">True</span>)
    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=<span class="keyword">False</span>)
    
    <span class="comment"># 4. Initialize model, optimizer, loss</span>
    model = ConnectFourNet().to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)
    criterion = nn.CrossEntropyLoss()
    
    <span class="comment"># 5. Training loop</span>
    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">1</span>, epochs + <span class="number">1</span>):
        model.train()
        total_loss = <span class="number">0.0</span>
        
        <span class="comment"># Iterate over batches</span>
        <span class="keyword">for</span> x, y <span class="keyword">in</span> train_loader:
            x = x.to(device)  <span class="comment"># (batch, 2, 4, 4)</span>
            y = y.to(device)  <span class="comment"># (batch,) with values 0-15</span>
            
            optimizer.zero_grad()       <span class="comment"># Clear gradients</span>
            logits = model(x)           <span class="comment"># Forward pass ‚Üí (batch, 16)</span>
            loss = criterion(logits, y) <span class="comment"># Compute loss</span>
            loss.backward()             <span class="comment"># Compute gradients</span>
            optimizer.step()            <span class="comment"># Update weights</span>
            
            total_loss += loss.item() * x.size(<span class="number">0</span>)
        
        avg_train_loss = total_loss / train_size
        
        <span class="comment"># 6. Validation</span>
        model.eval()
        correct = <span class="number">0</span>
        total = <span class="number">0</span>
        <span class="keyword">with</span> torch.no_grad():
            <span class="keyword">for</span> x, y <span class="keyword">in</span> val_loader:
                x = x.to(device)
                y = y.to(device)
                logits = model(x)
                preds = torch.argmax(logits, dim=<span class="number">1</span>)
                correct += (preds == y).sum().item()
                total += y.size(<span class="number">0</span>)
        
        val_acc = correct / total
        print(<span class="string">f"Epoch {epoch:02d} | Loss: {avg_train_loss:.4f} | Val Acc: {val_acc:.3f}"</span>)
    
    <span class="comment"># 7. Save model</span>
    torch.save(model.state_dict(), save_path)
                </div>
                
                <h3>6.3 Loss Function: CrossEntropyLoss</h3>
                
                <div class="info-box">
                    <h4>What is CrossEntropyLoss?</h4>
                    <p>CrossEntropyLoss measures how different the model's predictions are from the true labels. It's perfect for classification tasks like "which position should I choose?"</p>
                </div>
                
                <div class="math">
                    <strong>Mathematical Formula:</strong><br/><br/>
                    Loss = -log(P(correct position))<br/><br/>
                    
                    Where P(position i) = softmax(logits)·µ¢<br/><br/>
                    
                    <strong>Example:</strong><br/>
                    True position: 5<br/>
                    Model logits: [0.1, 0.3, -0.2, 0.8, 0.5, <strong>2.1</strong>, 0.4, ...]<br/>
                    After softmax: [0.05, 0.06, 0.04, 0.10, 0.07, <strong>0.35</strong>, 0.06, ...]<br/>
                    Loss = -log(0.35) ‚âà 1.05<br/><br/>
                    
                    <strong>Lower loss = Better predictions!</strong>
                </div>
                
                <h3>6.4 Optimizer: Adam</h3>
                
                <table class="data-table">
                    <thead>
                        <tr>
                            <th>Property</th>
                            <th>Value</th>
                            <th>Why This Choice?</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>Algorithm</td>
                            <td>Adam</td>
                            <td>Adaptive learning rates per parameter, fast convergence</td>
                        </tr>
                        <tr>
                            <td>Learning Rate</td>
                            <td>0.001</td>
                            <td>Balanced: not too fast (instability), not too slow</td>
                        </tr>
                        <tr>
                            <td>Beta1</td>
                            <td>0.9 (default)</td>
                            <td>Momentum for gradient averaging</td>
                        </tr>
                        <tr>
                            <td>Beta2</td>
                            <td>0.999 (default)</td>
                            <td>Second moment estimation</td>
                        </tr>
                    </tbody>
                </table>
                
                <h3>6.5 Training Metrics</h3>
                
                <div class="grid-container">
                    <div class="card">
                        <h4>üìâ Training Loss</h4>
                        <p>Measures prediction error on training data</p>
                        <p><strong>Goal:</strong> Decrease over time</p>
                        <p><strong>Typical:</strong> 2.0 ‚Üí 0.5 over 20 epochs</p>
                    </div>
                    
                    <div class="card">
                        <h4>‚úÖ Validation Accuracy</h4>
                        <p>% of correct position predictions</p>
                        <p><strong>Goal:</strong> Increase over time</p>
                        <p><strong>Typical:</strong> 0.2 ‚Üí 0.7 over 20 epochs</p>
                    </div>
                    
                    <div class="card">
                        <h4>‚è±Ô∏è Training Time</h4>
                        <p>Time per epoch varies with data size</p>
                        <p><strong>100 samples:</strong> ~1-2 seconds/epoch</p>
                        <p><strong>500 samples:</strong> ~5-10 seconds/epoch</p>
                    </div>
                </div>
                
                <div class="warning-box">
                    <h4>‚ö†Ô∏è Overfitting Warning</h4>
                    <p>If validation accuracy stops improving but training loss keeps decreasing, the model is <strong>overfitting</strong> (memorizing training data instead of learning patterns).</p>
                    <p><strong>Solutions:</strong></p>
                    <ul>
                        <li>Collect more diverse training data</li>
                        <li>Reduce number of epochs</li>
                        <li>Add regularization (dropout, weight decay)</li>
                    </ul>
                </div>
            </section>

            <!-- Section 7: Post-Training -->
            <section id="post-training" class="section">
                <h2>7. Post-Training: Model Deployment</h2>
                
                <h3>7.1 Model Saving</h3>
                <p>After training, the model's learned parameters are saved to a <code>.pth</code> file:</p>
                
                <div class="code-block">
<span class="comment"># Save model</span>
torch.save(model.state_dict(), <span class="string">"models/trained_model.pth"</span>)

<span class="comment"># File contents: Dictionary mapping layer names to learned weights</span>
{
    <span class="string">'conv1.weight'</span>: Tensor of shape [<span class="number">32</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>],
    <span class="string">'conv1.bias'</span>: Tensor of shape [<span class="number">32</span>],
    <span class="string">'conv2.weight'</span>: Tensor of shape [<span class="number">64</span>, <span class="number">32</span>, <span class="number">3</span>, <span class="number">3</span>],
    <span class="string">'conv2.bias'</span>: Tensor of shape [<span class="number">64</span>],
    <span class="string">'fc1.weight'</span>: Tensor of shape [<span class="number">128</span>, <span class="number">1024</span>],
    <span class="string">'fc1.bias'</span>: Tensor of shape [<span class="number">128</span>],
    <span class="string">'fc2.weight'</span>: Tensor of shape [<span class="number">16</span>, <span class="number">128</span>],
    <span class="string">'fc2.bias'</span>: Tensor of shape [<span class="number">16</span>]
}
                </div>
                
                <h3>7.2 Model Loading</h3>
                
                <div class="code-block">
<span class="comment"># File: src/agent.py</span>
<span class="keyword">def</span> <span class="function">load_model</span>(model_path, device=<span class="string">"cpu"</span>):
    <span class="comment"># 1. Create empty model architecture</span>
    model = ConnectFourNet().to(device)
    
    <span class="comment"># 2. Load learned weights from .pth file</span>
    state_dict = torch.load(model_path, map_location=device)
    model.load_state_dict(state_dict)
    
    <span class="comment"># 3. Set to evaluation mode (disables dropout, etc.)</span>
    model.eval()
    
    <span class="keyword">return</span> model
                </div>
                
                <h3>7.3 Inference (Making Predictions)</h3>
                
                <div class="code-block">
<span class="comment"># File: src/agent.py</span>
<span class="keyword">def</span> <span class="function">model_choose_action</span>(model, env, device=<span class="string">"cpu"</span>):
    <span class="comment"># 1. Get current board state</span>
    board, player = env.get_state()
    
    <span class="comment"># 2. Encode board to neural network format</span>
    x = encode_board(board, player).to(device)  <span class="comment"># (1, 2, 4, 4)</span>
    
    <span class="comment"># 3. Forward pass through network (no gradient computation)</span>
    <span class="keyword">with</span> torch.no_grad():
        logits = model(x)[<span class="number">0</span>]  <span class="comment"># (16,) - scores for each position</span>
    
    <span class="comment"># 4. Get valid positions (not occupied)</span>
    valid = env.valid_actions()  <span class="comment"># List of (row, col) tuples</span>
    valid_flat = [r * <span class="number">4</span> + c <span class="keyword">for</span> r, c <span class="keyword">in</span> valid]
    
    <span class="comment"># 5. Mask invalid positions (set to -infinity)</span>
    mask = torch.full_like(logits, float(<span class="string">"-inf"</span>))
    mask[valid_flat] = <span class="number">0.0</span>
    masked_logits = logits + mask
    
    <span class="comment"># 6. Convert to probabilities and choose best</span>
    probs = torch.softmax(masked_logits, dim=<span class="number">0</span>)
    flat_action = torch.argmax(probs).item()
    
    <span class="comment"># 7. Convert back to (row, col)</span>
    row = flat_action // <span class="number">4</span>
    col = flat_action % <span class="number">4</span>
    
    <span class="keyword">return</span> (row, col)
                </div>
                
                <h3>7.4 Inference Example</h3>
                
                <div class="info-box">
                    <h4>Step-by-Step Inference</h4>
                    
                    <p><strong>1. Board State:</strong></p>
                    <pre>
    [X] [ ] [ ] [ ]
    [ ] [O] [ ] [ ]
    [ ] [ ] [X] [ ]
    [ ] [ ] [ ] [ ]
                    </pre>
                    
                    <p><strong>2. Model Output (logits):</strong></p>
                    <pre>[0.5, 1.2, 0.3, 0.8, 0.9, -inf, 0.7, 1.5, 0.4, -inf, 0.6, 1.1, 0.2, 0.9, 0.5, 0.8]</pre>
                    <p><em>Position 0 (occupied by X): still has score, will be masked</em></p>
                    <p><em>Position 5 (occupied by O): -inf (already masked)</em></p>
                    
                    <p><strong>3. After Masking Occupied Positions:</strong></p>
                    <pre>[-inf, 1.2, 0.3, 0.8, 0.9, -inf, 0.7, 1.5, 0.4, -inf, 0.6, 1.1, 0.2, 0.9, 0.5, 0.8]</pre>
                    
                    <p><strong>4. After Softmax (probabilities):</strong></p>
                    <pre>[0, 0.15, 0.06, 0.10, 0.11, 0, 0.09, <strong>0.20</strong>, 0.07, 0, 0.08, 0.13, 0.05, 0.11, 0.07, 0.10]</pre>
                    
                    <p><strong>5. Best Move:</strong> Position 7 (row 1, col 3) with probability 0.20</p>
                </div>
                
                <h3>7.5 Deployment Options</h3>
                
                <div class="grid-container">
                    <div class="card">
                        <h4>üñ•Ô∏è Terminal Interface</h4>
                        <p><strong>Command:</strong> <code>python main.py play-model</code></p>
                        <p>Text-based game in terminal</p>
                        <p>Shows statistics and board</p>
                        <p>Good for testing</p>
                    </div>
                    
                    <div class="card">
                        <h4>üåê Web Interface (Streamlit)</h4>
                        <p><strong>Command:</strong> <code>python main.py streamlit</code></p>
                        <p>Visual web interface</p>
                        <p>Button-based interactions</p>
                        <p>Best user experience</p>
                    </div>
                    
                    <div class="card">
                        <h4>üîå API Integration</h4>
                        <p>Load model in your own code</p>
                        <p>Call <code>model_choose_action()</code></p>
                        <p>Integrate into larger systems</p>
                        <p>Flexible deployment</p>
                    </div>
                </div>
                
                <h3>7.6 Model Performance Analysis</h3>
                
                <div class="success-box">
                    <h4>‚úÖ Expected Performance</h4>
                    <p><strong>After 10 games training:</strong></p>
                    <ul>
                        <li>Validation Accuracy: 40-60%</li>
                        <li>Can make basic moves</li>
                        <li>May miss obvious strategies</li>
                    </ul>
                    
                    <p><strong>After 20 games training:</strong></p>
                    <ul>
                        <li>Validation Accuracy: 60-75%</li>
                        <li>Understands blocking</li>
                        <li>Attempts to create threats</li>
                    </ul>
                    
                    <p><strong>After 50+ games training:</strong></p>
                    <ul>
                        <li>Validation Accuracy: 70-85%</li>
                        <li>Strong tactical play</li>
                        <li>Imitates your style well</li>
                    </ul>
                </div>
            </section>

            <!-- Section 8: Mathematical Details -->
            <section id="mathematical" class="section">
                <h2>8. Mathematical Details</h2>
                
                <h3>8.1 Convolution Operation</h3>
                <div class="math">
                    <strong>2D Convolution Formula:</strong><br/><br/>
                    Output[i,j] = Œ£‚Çò Œ£‚Çô Input[i+m, j+n] √ó Kernel[m, n] + bias<br/><br/>
                    
                    Where:<br/>
                    - m, n iterate over kernel size (3√ó3 in our case)<br/>
                    - Padding ensures output size = input size
                </div>
                
                <h3>8.2 Parameter Count Calculation</h3>
                <div class="code-block">
<span class="comment"># Conv1: 2 input channels, 32 output channels, 3√ó3 kernel</span>
conv1_params = (<span class="number">2</span> * <span class="number">3</span> * <span class="number">3</span>) * <span class="number">32</span> + <span class="number">32</span> = <span class="number">608</span>
<span class="comment"># (input_channels √ó kernel_h √ó kernel_w) √ó output_channels + biases</span>

<span class="comment"># Conv2: 32 input channels, 64 output channels, 3√ó3 kernel</span>
conv2_params = (<span class="number">32</span> * <span class="number">3</span> * <span class="number">3</span>) * <span class="number">64</span> + <span class="number">64</span> = <span class="number">18,496</span>

<span class="comment"># FC1: 1024 input features, 128 output features</span>
fc1_params = <span class="number">1024</span> * <span class="number">128</span> + <span class="number">128</span> = <span class="number">131,200</span>

<span class="comment"># FC2: 128 input features, 16 output features</span>
fc2_params = <span class="number">128</span> * <span class="number">16</span> + <span class="number">16</span> = <span class="number">2,064</span>

<span class="comment"># Total</span>
total = <span class="number">608</span> + <span class="number">18,496</span> + <span class="number">131,200</span> + <span class="number">2,064</span> = <span class="number">152,368</span> parameters
                </div>
                
                <h3>8.3 Gradient Descent Update</h3>
                <div class="math">
                    <strong>Adam Optimizer Updates:</strong><br/><br/>
                    
                    1. Compute gradient: g = ‚àÇLoss/‚àÇŒ∏<br/>
                    2. Update first moment: m = Œ≤‚ÇÅ¬∑m + (1-Œ≤‚ÇÅ)¬∑g<br/>
                    3. Update second moment: v = Œ≤‚ÇÇ¬∑v + (1-Œ≤‚ÇÇ)¬∑g¬≤<br/>
                    4. Bias correction: mÃÇ = m/(1-Œ≤‚ÇÅ·µó), vÃÇ = v/(1-Œ≤‚ÇÇ·µó)<br/>
                    5. Update parameters: Œ∏ = Œ∏ - Œ±¬∑mÃÇ/‚àö(vÃÇ + Œµ)<br/><br/>
                    
                    Where:<br/>
                    - Œ± = learning rate (0.001)<br/>
                    - Œ≤‚ÇÅ = 0.9, Œ≤‚ÇÇ = 0.999<br/>
                    - Œµ = 10‚Åª‚Å∏ (numerical stability)
                </div>
            </section>

            <!-- Section 9: Performance -->
            <section id="performance" class="section">
                <h2>9. Performance Metrics</h2>
                
                <h3>9.1 Computational Complexity</h3>
                <table class="data-table">
                    <thead>
                        <tr>
                            <th>Operation</th>
                            <th>Time Complexity</th>
                            <th>Actual Time (CPU)</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>Data Loading</td>
                            <td>O(N)</td>
                            <td>~100ms for 100 samples</td>
                        </tr>
                        <tr>
                            <td>Single Forward Pass</td>
                            <td>O(1)</td>
                            <td>~2-5ms</td>
                        </tr>
                        <tr>
                            <td>Training Epoch</td>
                            <td>O(N/batch_size)</td>
                            <td>~1-2s for 100 samples</td>
                        </tr>
                        <tr>
                            <td>Full Training (20 epochs)</td>
                            <td>O(epochs √ó N)</td>
                            <td>~20-40s for 100 samples</td>
                        </tr>
                    </tbody>
                </table>
                
                <h3>9.2 Memory Requirements</h3>
                <table class="data-table">
                    <thead>
                        <tr>
                            <th>Component</th>
                            <th>Memory</th>
                            <th>Notes</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>Model Weights</td>
                            <td>~600 KB</td>
                            <td>152,368 params √ó 4 bytes</td>
                        </tr>
                        <tr>
                            <td>Training Data (100 samples)</td>
                            <td>~5 KB</td>
                            <td>Compressed NPZ format</td>
                        </tr>
                        <tr>
                            <td>Gradients (training)</td>
                            <td>~600 KB</td>
                            <td>Same size as weights</td>
                        </tr>
                        <tr>
                            <td>Activations (batch=64)</td>
                            <td>~50 MB</td>
                            <td>Temporary during training</td>
                        </tr>
                    </tbody>
                </table>
                
                <h3>9.3 Scalability</h3>
                <div class="grid-container">
                    <div class="card">
                        <h4>üìà Data Scaling</h4>
                        <p>Linear relationship: 2√ó data = 2√ó training time</p>
                        <p>Recommended: 100-500 moves for good performance</p>
                    </div>
                    
                    <div class="card">
                        <h4>üöÄ Inference Speed</h4>
                        <p>~200-500 moves per second (CPU)</p>
                        <p>~2,000-5,000 moves per second (GPU)</p>
                    </div>
                    
                    <div class="card">
                        <h4>üí™ Model Capacity</h4>
                        <p>Can learn complex patterns</p>
                        <p>152K parameters sufficient for 4√ó4 board</p>
                    </div>
                </div>
            </section>

            <!-- Summary -->
            <section class="section" style="border-left-color: #28a745;">
                <h2 style="color: #28a745; border-color: #28a745;">üìö Summary</h2>
                
                <div class="success-box">
                    <h4>üéØ Complete Pipeline</h4>
                    <ol>
                        <li><strong>Collect Data:</strong> Human plays games ‚Üí Record board states and moves</li>
                        <li><strong>Store Data:</strong> Save to NPZ format (boards, players, actions)</li>
                        <li><strong>Transform Data:</strong> Convert to 2-channel representation (current/opponent)</li>
                        <li><strong>Train Model:</strong> CNN learns to predict human moves from board states</li>
                        <li><strong>Save Model:</strong> Export learned weights to .pth file</li>
                        <li><strong>Deploy Model:</strong> Load and use for inference in games</li>
                    </ol>
                </div>
                
                <h3>Key Takeaways</h3>
                <ul>
                    <li>‚úÖ <strong>Imitation Learning:</strong> AI learns by copying human behavior</li>
                    <li>‚úÖ <strong>CNN Architecture:</strong> Perfect for spatial pattern recognition</li>
                    <li>‚úÖ <strong>Two-Channel Encoding:</strong> Perspective-independent representation</li>
                    <li>‚úÖ <strong>CrossEntropyLoss:</strong> Measures prediction accuracy</li>
                    <li>‚úÖ <strong>Adam Optimizer:</strong> Efficient gradient-based learning</li>
                    <li>‚úÖ <strong>Masked Softmax:</strong> Only choose valid positions during play</li>
                </ul>
            </section>
        </div>

        <footer>
            <p>Connect 3 AI - Technical Documentation</p>
            <p>Built with PyTorch | Designed for Education</p>
            <p>¬© 2025 | Created for PyTorch Learning</p>
        </footer>
    </div>
</body>
</html>

